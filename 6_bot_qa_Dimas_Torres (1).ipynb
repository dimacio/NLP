{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfa39F4lsLf3"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## LSTM Bot QA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqO0PRcFsPTe"
      },
      "source": [
        "### Datos\n",
        "El objecto es utilizar datos disponibles del challenge ConvAI2 (Conversational Intelligence Challenge 2) de conversaciones en inglés. Se construirá un BOT para responder a preguntas del usuario (QA).\\\n",
        "[LINK](http://convai.io/data/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bDFC0I3j9oFD"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --no-cache-dir gdown --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras.preprocessing\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MeGdqgdtkU4",
        "outputId": "bedb26a1-fb0d-4c88-8f14-9eb8a18175ca"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras.preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from keras.preprocessing) (2.0.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from keras.preprocessing) (1.17.0)\n",
            "Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras.preprocessing\n",
            "Successfully installed keras.preprocessing-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions --quiet\n",
        "!pip install nltk --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08ngNKJvh70V",
        "outputId": "63502d51-dd4a-4d3c-9971-05410c8420db"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/289.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/118.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.3/118.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cq3YXak9sGHd"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "import gdown\n",
        "import contractions # For better contraction handling\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Configuration ---\n",
        "config = {\n",
        "    \"dataset_url\": 'https://drive.google.com/uc?id=1awUxYwImF84MIT5-jCaYAPe2QwSgS1hN&export=download',\n",
        "    \"dataset_filename\": 'data_volunteers.json',\n",
        "    \"glove_url\": \"http://nlp.stanford.edu/data/glove.6B.zip\",\n",
        "    \"glove_zip\": \"glove.6B.zip\",\n",
        "    \"glove_file\": \"glove.6B.100d.txt\",\n",
        "    \"embedding_dim\": 100,\n",
        "    \"max_vocab_size\": 15000, # Increased vocab size slightly\n",
        "    \"max_input_token_len\": 40, # Filter based on tokens now\n",
        "    \"max_output_token_len\": 40, # Filter based on tokens now\n",
        "    \"lstm_units\": 384, # Increased units slightly from 256\n",
        "    \"dropout_rate\": 0.3, # Added dropout\n",
        "    \"recurrent_dropout_rate\": 0.3, # Added recurrent dropout\n",
        "    \"batch_size\": 64,\n",
        "    \"epochs\": 100, # Increased epochs, but EarlyStopping will control duration\n",
        "    \"validation_split\": 0.2,\n",
        "    \"early_stopping_patience\": 10,\n",
        "    \"lr_plateau_patience\": 5,\n",
        "    \"lr_plateau_factor\": 0.2,\n",
        "}\n"
      ],
      "metadata": {
        "id": "-_NbH5B4iKXj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Download NLTK Data\n",
        "import nltk\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:  # Catch LookupError for missing resource\n",
        "    nltk.download('punkt')\n",
        "try:\n",
        "    nltk.data.find('corpora/wordnet')\n",
        "except LookupError:  # Catch LookupError here as well\n",
        "    nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_U7joyERiPTo",
        "outputId": "ec553640-3527-43ec-c281-01b8315fd4bb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RHNkUaPp6aYq"
      },
      "outputs": [],
      "source": [
        "# --- Helper Functions ---\n",
        "\n",
        "def download_file(url, output_filename, desc=\"file\"):\n",
        "    \"\"\"Downloads a file if it doesn't exist.\"\"\"\n",
        "    if not os.path.exists(output_filename):\n",
        "        print(f\"Downloading {desc}...\")\n",
        "        gdown.download(url, output_filename, quiet=False)\n",
        "    else:\n",
        "        print(f\"{desc} already downloaded: {output_filename}\")\n",
        "\n",
        "def download_and_extract_zip(url, output_zip, extracted_file, desc=\"zip file\"):\n",
        "    \"\"\"Downloads and extracts a zip file if the target file doesn't exist.\"\"\"\n",
        "    if not os.path.exists(extracted_file):\n",
        "        if not os.path.exists(output_zip):\n",
        "             print(f\"Downloading {desc}...\")\n",
        "             gdown.download(url, output_zip, quiet=False)\n",
        "        else:\n",
        "            print(f\"{desc} already downloaded: {output_zip}\")\n",
        "\n",
        "        print(f\"Extracting {output_zip}...\")\n",
        "        import zipfile\n",
        "        with zipfile.ZipFile(output_zip, 'r') as zip_ref:\n",
        "            zip_ref.extractall('.')\n",
        "        print(f\"Extracted to current directory.\")\n",
        "        if not os.path.exists(extracted_file):\n",
        "             print(f\"Warning: Expected extracted file {extracted_file} not found after extraction.\")\n",
        "    else:\n",
        "        print(f\"Required file already exists: {extracted_file}\")\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WZy1-wgG-Rp7"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Cleans text data: lowercase, expand contractions, lemmatize, remove non-alphanumeric (keep spaces).\n",
        "    Handles the bug from the original script and uses lemmatization.\n",
        "    \"\"\"\n",
        "    text = text.lower()\n",
        "    # Expand contractions (more robustly)\n",
        "    text = contractions.fix(text)\n",
        "    # Lemmatize: asocio los token con raices comunes, como diferentes conjugaciones de un mismo verbo\n",
        "    tokens = word_tokenize(text)\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    text = ' '.join(lemmatized_tokens)\n",
        "    # Keep only alphanumeric and spaces, replace others with space\n",
        "    text = re.sub(r'[^a-z0-9\\s]', ' ', text)\n",
        "    # Remove extra spaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ue5qd54S-eew"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_data(filename, max_input_len, max_output_len):\n",
        "    \"\"\"\n",
        "    Loads data, cleans text, creates input/output pairs, and filters by TOKEN length.\n",
        "    \"\"\"\n",
        "    print(\"Loading and preprocessing data...\")\n",
        "    with open(filename) as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    input_texts = []\n",
        "    output_texts_input = [] # Decoder input (<sos> + sentence)\n",
        "    output_texts_target = [] # Decoder target (sentence + <eos>)\n",
        "\n",
        "    skipped_count = 0\n",
        "    total_pairs = 0\n",
        "\n",
        "    for conversation in data:\n",
        "      #las pares con respuestas y las impares preguntas\n",
        "        for i in range(len(conversation['dialog']) - 1):\n",
        "            total_pairs += 1\n",
        "            input_raw = conversation['dialog'][i]['text']\n",
        "            output_raw = conversation['dialog'][i+1]['text']\n",
        "\n",
        "            # Clean texts\n",
        "            input_cleaned = clean_text(input_raw)\n",
        "            output_cleaned = clean_text(output_raw)\n",
        "\n",
        "            # Tokenize temporarily for length check\n",
        "            input_tokens = input_cleaned.split()\n",
        "            output_tokens = output_cleaned.split()\n",
        "\n",
        "            # Filter based on TOKEN length\n",
        "            if len(input_tokens) > max_input_len or len(output_tokens) > max_output_len \\\n",
        "               or not input_tokens or not output_tokens: # Skip empty sequences\n",
        "                skipped_count += 1\n",
        "                continue\n",
        "\n",
        "            # Prepare decoder input and target\n",
        "            output_input = '<sos> ' + output_cleaned\n",
        "            output_target = output_cleaned + ' <eos>'\n",
        "\n",
        "            input_texts.append(input_cleaned)\n",
        "            output_texts_input.append(output_input)\n",
        "            output_texts_target.append(output_target)\n",
        "\n",
        "    print(f\"Total potential pairs: {total_pairs}\")\n",
        "    print(f\"Pairs skipped due to length/emptiness: {skipped_count}\")\n",
        "    print(f\"Pairs used for training: {len(input_texts)}\")\n",
        "    return input_texts, output_texts_input, output_texts_target\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P-ynUNP5xp6"
      },
      "source": [
        "### 2 - Preprocesamiento\n",
        "Realizar el preprocesamiento necesario para obtener:\n",
        "- word2idx_inputs, max_input_len\n",
        "- word2idx_outputs, max_out_len, num_words_output\n",
        "- encoder_input_sequences, decoder_output_sequences, decoder_targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jHBRAXPl-3dz"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_pad(input_texts, output_texts_input, output_texts_target,\n",
        "                     max_vocab_size, max_input_len, max_output_len):\n",
        "    \"\"\"\n",
        "    Tokenizes text, pads sequences, and returns tokenizers and processed sequences.\n",
        "    Uses separate tokenizers, handles <unk>, uses pre-padding for encoder.\n",
        "    \"\"\"\n",
        "    print(\"Tokenizing and padding sequences...\")\n",
        "\n",
        "    # Input Tokenizer (Encoder)\n",
        "    tokenizer_inputs = Tokenizer(num_words=max_vocab_size, oov_token='<unk>')\n",
        "    tokenizer_inputs.fit_on_texts(input_texts)\n",
        "    encoder_input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)\n",
        "    encoder_input_sequences = pad_sequences(encoder_input_sequences, maxlen=max_input_len, padding='pre') # Pre-padding for encoder\n",
        "    word2idx_inputs = tokenizer_inputs.word_index\n",
        "    # Uso prepadding porque como es la última neurona la que pasa su estado al decoder puede ser que se diluya la información valiosa en los pasos que hace sobre el padding\n",
        "    num_words_inputs = min(max_vocab_size, len(word2idx_inputs) + 1)\n",
        "    print(f\"Input Vocab Size (used): {num_words_inputs-1} (+1 for padding)\")\n",
        "\n",
        "\n",
        "    # Output Tokenizer (Decoder) - Fit on both input and target to include <sos> and <eos>\n",
        "    # filters='' ensures '<sos>' and '<eos>' are kept\n",
        "    tokenizer_outputs = Tokenizer(num_words=max_vocab_size, oov_token='<unk>', filters='')\n",
        "    tokenizer_outputs.fit_on_texts(output_texts_input + output_texts_target)\n",
        "    decoder_input_sequences = tokenizer_outputs.texts_to_sequences(output_texts_input)\n",
        "    decoder_target_sequences = tokenizer_outputs.texts_to_sequences(output_texts_target)\n",
        "\n",
        "    decoder_input_sequences = pad_sequences(decoder_input_sequences, maxlen=max_output_len, padding='post')\n",
        "    decoder_target_sequences = pad_sequences(decoder_target_sequences, maxlen=max_output_len, padding='post') # Target uses post-padding\n",
        "\n",
        "    word2idx_outputs = tokenizer_outputs.word_index\n",
        "    idx2word_outputs = {v: k for k, v in word2idx_outputs.items()} # For decoding\n",
        "    num_words_outputs = min(max_vocab_size, len(word2idx_outputs) + 1)\n",
        "    print(f\"Output Vocab Size (used): {num_words_outputs-1} (+1 for padding, includes <sos>, <eos>)\")\n",
        "\n",
        "\n",
        "    return (tokenizer_inputs, tokenizer_outputs,\n",
        "            encoder_input_sequences, decoder_input_sequences, decoder_target_sequences,\n",
        "            word2idx_inputs, word2idx_outputs, idx2word_outputs,\n",
        "            num_words_inputs, num_words_outputs,\n",
        "            max_input_len, max_output_len)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CJIsLBbj6rg"
      },
      "source": [
        "### 3 - Preparar los embeddings\n",
        "Utilizar los embeddings de Glove o FastText para transformar los tokens de entrada en vectores"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_glove_embeddings(glove_file):\n",
        "    \"\"\"Loads GloVe embeddings from a file into a dictionary.\"\"\"\n",
        "    print(f\"Loading GloVe embeddings from: {glove_file}\")\n",
        "    embeddings_index = {}\n",
        "    try:\n",
        "        with open(glove_file, 'r', encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                values = line.split()\n",
        "                word = values[0]\n",
        "                coefs = np.asarray(values[1:], dtype='float32')\n",
        "                embeddings_index[word] = coefs\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: GloVe file not found at {glove_file}\")\n",
        "        print(\"Please ensure the GloVe file is downloaded and extracted correctly.\")\n",
        "        return None\n",
        "    print(f\"Found {len(embeddings_index)} word vectors in GloVe.\")\n",
        "    return embeddings_index"
      ],
      "metadata": {
        "id": "M3ZqLzwfUo53"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "07L1qj8pC_l6"
      },
      "outputs": [],
      "source": [
        "def build_embedding_matrix(word_index, embeddings_index, embedding_dim, max_vocab_size):\n",
        "    \"\"\"\n",
        "    Builds an embedding matrix using pre-trained GloVe vectors.\n",
        "    Handles OOV words by initializing with the mean embedding vector.\n",
        "    \"\"\"\n",
        "    print(\"Building embedding matrix...\")\n",
        "    num_words = min(max_vocab_size, len(word_index) + 1)\n",
        "    embedding_matrix = np.zeros((num_words, embedding_dim))\n",
        "    found_vectors = []\n",
        "\n",
        "    for word, i in word_index.items():\n",
        "        if i >= num_words:\n",
        "            continue\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            # Words not found in embedding index will be all-zeros.\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "            found_vectors.append(embedding_vector)\n",
        "\n",
        "    # Calculate mean vector for OOV initialization (excluding zero vectors)\n",
        "    if found_vectors:\n",
        "       mean_vector = np.mean(found_vectors, axis=0)\n",
        "    else:\n",
        "       mean_vector = np.random.randn(embedding_dim) * 0.01 # Fallback: small random\n",
        "       print(\"Warning: No pre-trained vectors found for vocabulary. Using random init for OOV.\")\n",
        "\n",
        "\n",
        "    # Initialize OOV tokens (index 1 for <unk> by default in Keras Tokenizer)\n",
        "    # and any other words that weren't found and are still zeros.\n",
        "    # Also initialize padding token (index 0) just in case, though mask_zero should handle it.\n",
        "    for i in range(num_words):\n",
        "       if np.all(embedding_matrix[i] == 0):\n",
        "           if i == word_index.get('<unk>', -1): # Check if it's the explicit OOV token\n",
        "               embedding_matrix[i] = mean_vector\n",
        "               print(f\"Initialized <unk> embedding (index {i}) with mean vector.\")\n",
        "           elif i != 0: # Don't override padding token 0 with mean\n",
        "               embedding_matrix[i] = mean_vector # Initialize other missed words\n",
        "\n",
        "\n",
        "    print(f\"Embedding matrix shape: {embedding_matrix.shape}\")\n",
        "    coverage = len(found_vectors) / (num_words - 2) if (num_words - 2) > 0 else 0 # Exclude padding and potential <unk>\n",
        "    print(f\"Vocabulary coverage by GloVe: {coverage:.2%}\")\n",
        "    return embedding_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh9uqqizk8VD"
      },
      "source": [
        "### 4 - Entrenar el modelo\n",
        "Entrenar un modelo basado en el esquema encoder-decoder utilizando los datos generados en los puntos anteriores. Utilce como referencias los ejemplos vistos en clase."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_seq2seq_model(max_input_len, max_output_len, num_words_inputs, num_words_outputs,\n",
        "                        embedding_dim, lstm_units, dropout_rate, recurrent_dropout_rate,\n",
        "                        input_embedding_matrix, output_embedding_matrix):\n",
        "    \"\"\"\n",
        "    Builds the standard Encoder-Decoder model\n",
        "    Uses fine-tunable embeddings for both encoder and decoder.\n",
        "    Includes Dropout and Recurrent Dropout.\n",
        "    \"\"\"\n",
        "    print(\"Building Seq2Seq model\")\n",
        "\n",
        "    # --- Encoder ---\n",
        "    encoder_inputs = Input(shape=(max_input_len,), name='encoder_input')\n",
        "    # Use mask_zero=True for pre-padding\n",
        "    enc_emb_layer = Embedding(num_words_inputs, embedding_dim, weights=[input_embedding_matrix],\n",
        "                              trainable=True, mask_zero=True, name='encoder_embedding')\n",
        "    enc_emb = enc_emb_layer(encoder_inputs)\n",
        "    # Encoder LSTM: Only need the final states, not the full sequence output\n",
        "    encoder_lstm = LSTM(lstm_units, return_state=True, # return_sequences=False by default is ok, but explicitly set to True for clarity\n",
        "                        dropout=dropout_rate, recurrent_dropout=recurrent_dropout_rate, name='encoder_lstm')\n",
        "    # We discard the encoder outputs sequence, only keep the states\n",
        "    _, state_h, state_c = encoder_lstm(enc_emb)\n",
        "    encoder_states = [state_h, state_c] # Context vector (last state)\n",
        "\n",
        "    # --- Decoder ---\n",
        "    decoder_inputs = Input(shape=(max_output_len,), name='decoder_input') # Shape for teacher forcing during training\n",
        "    # Decoder embedding can also be fine-tuned\n",
        "    dec_emb_layer = Embedding(num_words_outputs, embedding_dim, weights=[output_embedding_matrix],\n",
        "                              trainable=True, mask_zero=False, name='decoder_embedding') # No mask_zero for post-padding target\n",
        "    dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "    # Decoder LSTM - returns full sequence for Teacher Forcing alignment\n",
        "    # Takes the encoder's final states as its initial state\n",
        "    decoder_lstm = LSTM(lstm_units, return_sequences=True, return_state=True, # Need sequences for Dense layer over time\n",
        "                        dropout=dropout_rate, recurrent_dropout=recurrent_dropout_rate, name='decoder_lstm')\n",
        "    # decoder_lstm_outputs shape: (batch_size, max_output_len, lstm_units)\n",
        "    decoder_lstm_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
        "\n",
        "    # --- Output Layer ---\n",
        "    # Dense layer applied directly to the Decoder LSTM outputs\n",
        "\n",
        "    decoder_dense = Dense(num_words_outputs, activation='softmax', name='decoder_output_dense')\n",
        "    decoder_outputs = decoder_dense(decoder_lstm_outputs) # Apply Dense to the LSTM sequence output\n",
        "\n",
        "    # --- Training Model Definition ---\n",
        "    # Inputs: Encoder sequence, Decoder sequence (for teacher forcing)\n",
        "    # Outputs: Probability distribution over vocab for each timestep in the output sequence\n",
        "    training_model = Model([encoder_inputs, decoder_inputs], decoder_outputs, name='training_model')\n",
        "\n",
        "    # Compile using sparse categorical crossentropy\n",
        "    training_model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    print(\"Model built successfully\")\n",
        "    training_model.summary() # Print model summary\n",
        "    return training_model"
      ],
      "metadata": {
        "id": "wp7CVLKNjPOz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, encoder_input_data, decoder_input_data, decoder_target_data,\n",
        "                batch_size, epochs, validation_split, early_stopping_patience,\n",
        "                lr_plateau_patience, lr_plateau_factor):\n",
        "    \"\"\"Trains the model with callbacks.\"\"\"\n",
        "    print(\"Starting model training...\")\n",
        "\n",
        "    # Callbacks\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=early_stopping_patience,\n",
        "                                   verbose=1, restore_best_weights=True)\n",
        "    # Disminuyo la tasa de aprendizaje cuando no veo mejoras para que explore con mas detenimiento el espacio local\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=lr_plateau_factor,\n",
        "                                  patience=lr_plateau_patience, min_lr=1e-6, verbose=1)\n",
        "\n",
        "    history = model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "                        batch_size=batch_size,\n",
        "                        epochs=epochs,\n",
        "                        validation_split=validation_split,\n",
        "                        callbacks=[early_stopping, reduce_lr])\n",
        "\n",
        "    print(\"Training finished.\")\n",
        "    return history"
      ],
      "metadata": {
        "id": "UUWlysXej08L"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbwn0ekDy_s2"
      },
      "source": [
        "### 5 - Inferencia\n",
        "Experimentar el funcionamiento de su modelo. Recuerde que debe realizar la inferencia de los modelos por separado de encoder y decoder."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_inference_models(training_model, lstm_units):\n",
        "    \"\"\"\n",
        "    Builds separate encoder and decoder models for inference for a standard Seq2Seq model.\n",
        "    \"\"\"\n",
        "    print(\"Building inference models\")\n",
        "\n",
        "   # --- Encoder Model ---\n",
        "    # The encoder's role is just to produce the final context states (h, c)\n",
        "    # Get the input layer of the training model by name\n",
        "    encoder_inputs = training_model.get_layer('encoder_input').output\n",
        "    # Get the encoder LSTM layer by name\n",
        "    encoder_lstm_layer = training_model.get_layer('encoder_lstm')\n",
        "    # Get the encoder embedding layer by name\n",
        "    encoder_embedding_layer = training_model.get_layer('encoder_embedding')\n",
        "\n",
        "    # Apply the embedding layer to the encoder inputs\n",
        "    # Changed: Apply the embedding layer inside the Model definition\n",
        "    # enc_emb = encoder_embedding_layer(encoder_inputs)\n",
        "\n",
        "    # Get the encoder LSTM outputs (output sequence, state_h, state_c)\n",
        "    # Changed: Pass encoder_inputs directly to the LSTM through the embedding layer\n",
        "    # Applying embedding layer here, removed unnecessary encoder_outputs_seq\n",
        "    enc_emb = encoder_embedding_layer(encoder_inputs)\n",
        "    _, state_h_enc, state_c_enc = encoder_lstm_layer(enc_emb)\n",
        "    encoder_states = [state_h_enc, state_c_enc]  # Context vector (last state)\n",
        "\n",
        "    # Define the encoder model: Input sequence -> Output states [h, c]\n",
        "    encoder_model = Model(encoder_inputs, encoder_states, name='encoder_inference')\n",
        "    print(\"Encoder inference model built.\")\n",
        "\n",
        "\n",
        "   # --- Decoder Model ---\n",
        "    # Inputs needed for the decoder at each step:\n",
        "    # 1. The previous predicted token (or <sos> initially)\n",
        "    # 2. The previous hidden state (h)\n",
        "    # 3. The previous cell state (c)\n",
        "\n",
        "    # Define input layers for the states\n",
        "    decoder_state_input_h = Input(shape=(lstm_units,), name='decoder_state_h_input')\n",
        "    decoder_state_input_c = Input(shape=(lstm_units,), name='decoder_state_c_input')\n",
        "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "    # Input for the single token prediction at each step\n",
        "    decoder_inputs_single = Input(shape=(1,), name='decoder_token_input') # Input is one token ID\n",
        "\n",
        "    # Get layers from the trained model\n",
        "    dec_emb_layer = training_model.get_layer('decoder_embedding')\n",
        "    decoder_lstm = training_model.get_layer('decoder_lstm') # The actual LSTM layer\n",
        "    decoder_dense = training_model.get_layer('decoder_output_dense') # The final classification layer\n",
        "\n",
        "    # Inference Decoder Steps:\n",
        "    # 1. Embed the input token\n",
        "    dec_emb_single = dec_emb_layer(decoder_inputs_single)\n",
        "\n",
        "    # 2. Run the LSTM step using the embedded token and the previous states\n",
        "    # We get the output for this step and the new states\n",
        "    decoder_lstm_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "        dec_emb_single, initial_state=decoder_states_inputs\n",
        "    )\n",
        "    decoder_states = [state_h_dec, state_c_dec] # New states to pass to the next step\n",
        "\n",
        "    # 3. Apply the Dense layer to the LSTM output to get token probabilities\n",
        "    decoder_outputs = decoder_dense(decoder_lstm_outputs)\n",
        "\n",
        "    # Define the decoder model:\n",
        "    # Inputs: [Single Token Input, Previous Hidden State, Previous Cell State]\n",
        "    # Outputs: [Token Probabilities, New Hidden State, New Cell State]\n",
        "    decoder_model = Model(\n",
        "        [decoder_inputs_single] + decoder_states_inputs,\n",
        "        [decoder_outputs] + decoder_states,\n",
        "        name='decoder_inference'\n",
        "    )\n",
        "    print(\"Decoder inference model built.\")\n",
        "\n",
        "    return encoder_model, decoder_model"
      ],
      "metadata": {
        "id": "kE0Wa4eSj2iP"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence_greedy(input_seq, encoder_model, decoder_model,\n",
        "                       tokenizer_outputs, idx2word_outputs, max_output_len):\n",
        "    \"\"\"Decodes an input sequence using greedy search.\"\"\"\n",
        "\n",
        "    # Encode the input sequence to get the initial states\n",
        "    # Removed encoder_outputs_seq\n",
        "    states_value = encoder_model.predict(input_seq, verbose=0)\n",
        "\n",
        "    # Start sequence with '<sos>' token\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = tokenizer_outputs.word_index['<sos>']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = []\n",
        "\n",
        "    while not stop_condition:\n",
        "        # Predict next token (probabilities) and update states\n",
        "        # Removed encoder_outputs_seq from predict call\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value, verbose=0\n",
        "        )\n",
        "\n",
        "        # Get the most likely token ID (greedy)\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        # Use efficient dictionary lookup\n",
        "        sampled_word = idx2word_outputs.get(sampled_token_index, '<unk>')\n",
        "\n",
        "        # Stop if '<eos>' is sampled or max length is reached\n",
        "        if sampled_word == '<eos>' or len(decoded_sentence) >= max_output_len:\n",
        "            stop_condition = True\n",
        "        else:\n",
        "            decoded_sentence.append(sampled_word)\n",
        "\n",
        "        # Update the target sequence for the next step\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return ' '.join(decoded_sentence)"
      ],
      "metadata": {
        "id": "5HAblFuFj7po"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejecución general"
      ],
      "metadata": {
        "id": "RLF1M3gslZ4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Main Execution ---\n",
        "nltk.download('punkt_tab')\n",
        "# --- 1. Download Data ---\n",
        "download_file(config['dataset_url'], config['dataset_filename'], desc=\"Dataset\")\n",
        "download_and_extract_zip(config['glove_url'], config['glove_zip'], config['glove_file'], desc=\"GloVe Embeddings\")\n",
        "\n",
        "# --- 2. Load and Preprocess ---\n",
        "input_texts, output_texts_input, output_texts_target = load_and_preprocess_data(\n",
        "    config['dataset_filename'],\n",
        "    config['max_input_token_len'],\n",
        "    config['max_output_token_len']\n",
        ")\n",
        "\n",
        "if not input_texts:\n",
        "    print(\"No data loaded after preprocessing. Check filtering criteria or dataset.\")\n",
        "    exit()\n",
        "\n",
        "# --- 3. Tokenize and Pad ---\n",
        "(tokenizer_inputs, tokenizer_outputs,\n",
        " encoder_input_sequences, decoder_input_sequences, decoder_target_sequences,\n",
        " word2idx_inputs, word2idx_outputs, idx2word_outputs,\n",
        " num_words_inputs, num_words_outputs,\n",
        " max_input_len, max_output_len) = tokenize_and_pad(\n",
        "    input_texts, output_texts_input, output_texts_target,\n",
        "    config['max_vocab_size'], config['max_input_token_len'], config['max_output_token_len']\n",
        ")\n",
        "\n",
        "# --- 4. Prepare Embeddings ---\n",
        "embeddings_index = load_glove_embeddings(config['glove_file'])\n",
        "if embeddings_index is None:\n",
        "    exit()\n",
        "\n",
        "input_embedding_matrix = build_embedding_matrix(\n",
        "    word2idx_inputs, embeddings_index, config['embedding_dim'], num_words_inputs\n",
        ")\n",
        "output_embedding_matrix = build_embedding_matrix(\n",
        "    word2idx_outputs, embeddings_index, config['embedding_dim'], num_words_outputs\n",
        ")\n",
        "\n",
        "# --- 5. Build Model ---\n",
        "training_model = build_seq2seq_model(\n",
        "    max_input_len, max_output_len, # Use actual padded lengths\n",
        "    num_words_inputs, num_words_outputs, # Use actual vocab sizes\n",
        "    config['embedding_dim'], config['lstm_units'],\n",
        "    config['dropout_rate'], config['recurrent_dropout_rate'],\n",
        "    input_embedding_matrix, output_embedding_matrix\n",
        ")\n",
        "\n",
        "# --- 6. Train Model ---\n",
        "# Note: decoder_target_sequences does not need to be one-hot encoded when using sparse_categorical_crossentropy\n",
        "history = train_model(\n",
        "    training_model,\n",
        "    encoder_input_sequences, decoder_input_sequences, decoder_target_sequences,\n",
        "    config['batch_size'], config['epochs'], config['validation_split'],\n",
        "    config['early_stopping_patience'], config['lr_plateau_patience'], config['lr_plateau_factor']\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "eGMqO-sCkASQ",
        "outputId": "c5d87de9-7ac6-406d-a22f-e4687c05e05c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset already downloaded: data_volunteers.json\n",
            "Required file already exists: glove.6B.100d.txt\n",
            "Loading and preprocessing data...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-46234269a53a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# --- 2. Load and Preprocess ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m input_texts, output_texts_input, output_texts_target = load_and_preprocess_data(\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset_filename'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_input_token_len'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-d03ccb5980d5>\u001b[0m in \u001b[0;36mload_and_preprocess_data\u001b[0;34m(filename, max_input_len, max_output_len)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m# Clean texts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0minput_cleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0moutput_cleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;31m# Tokenize temporarily for length check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-abb718f94b9c>\u001b[0m in \u001b[0;36mclean_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontractions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Lemmatize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mlemmatized_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmatized_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \"\"\"\n\u001b[1;32m    142\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     return [\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     ]\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     return [\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     ]\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/tokenize/destructive.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, convert_parentheses, return_str)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mregexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubstitution\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTARTING_QUOTES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubstitution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mregexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubstitution\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPUNCTUATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/re/__init__.py\u001b[0m in \u001b[0;36m_subx\u001b[0;34m(pattern, template)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_subx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0;31m# internal: Pattern.sub/subn implementation helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m     \u001b[0mtemplate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_compile_repl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;31m# literal replacement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training history\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "uG-VtmG_wfUm",
        "outputId": "4e73def3-2e5d-4414-871e-dbe143a84429"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pudo haber un overfitting\n"
      ],
      "metadata": {
        "id": "NkosBsEawwQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # --- 7. Build Inference Models ---\n",
        "encoder_inf_model, decoder_inf_model = build_inference_models(\n",
        "    training_model, config['lstm_units']\n",
        ")\n",
        "\n",
        "# --- 8. Inference Example ---\n",
        "print(\"\\n--- Inference Examples ---\")\n",
        "# Select a few random samples from the validation set (if split used during training)\n",
        "# or just from the original data\n",
        "num_examples = 5\n",
        "for i in np.random.choice(len(encoder_input_sequences), num_examples, replace=False):\n",
        "    input_seq = encoder_input_sequences[i:i+1] # Need batch dimension\n",
        "    original_input_text = input_texts[i]\n",
        "    # Find corresponding original target text (needs careful alignment if validation split was random)\n",
        "    # For simplicity, let's just show the input and decoded output\n",
        "    # original_output_text = output_texts_target[i].replace('<eos>', '').strip() # Example if aligned\n",
        "\n",
        "    decoded_sentence = decode_sequence_greedy(\n",
        "        input_seq, encoder_inf_model, decoder_inf_model,\n",
        "        tokenizer_outputs, idx2word_outputs, max_output_len\n",
        "    )\n",
        "    print(f\"Input:   {original_input_text}\")\n",
        "    # print(f\"Original: {original_output_text}\") # Uncomment if you have aligned target\n",
        "    print(f\"Decoded: {decoded_sentence}\")\n",
        "    print(\"-\" * 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-nRt-9LwXat",
        "outputId": "678c9595-0da7-461c-f62e-b859516a9db8"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building inference models\n",
            "Encoder inference model built.\n",
            "Decoder inference model built.\n",
            "\n",
            "--- Inference Examples ---\n",
            "Input:   i got a job on a gas station i am an engineer\n",
            "Decoded: that is cool i am a teacher\n",
            "------------------------------\n",
            "Input:   i will send you my resume\n",
            "Decoded: what do you do for a living\n",
            "------------------------------\n",
            "Input:   yes they are what do you like to do\n",
            "Decoded: i do not know what that mean\n",
            "------------------------------\n",
            "Input:   do you like car i am a car salesman\n",
            "Decoded: i do not have a lot of time for that\n",
            "------------------------------\n",
            "Input:   great i play guitar and play game a my hobby\n",
            "Decoded: i love to read\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo responde con una gramática bastante buena, pero no llega a ser un dialogo de pregunta y respuesta. Puede ser porque se removieron los signos de pregunta en el preprocesamiento y eso es lo que marcaba la cadencia."
      ],
      "metadata": {
        "id": "wVc9j1A719ta"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0DkZilnX2X3K"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}